---
title: "Crime Analysis in Austin: Patterns in Time and Location"
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,  
                      warning = FALSE, message = FALSE, 
                      fig.align = "center",
                      R.options = list(max.print=100))
```

# Connor Shen, cs65692

### Introduction:

Crime is a complex issue affecting communities worldwide, with patterns that often reflect underlying socio-economic and environmental factors. Understanding these patterns can support more effective public safety strategies. This project uses the **Austin Crime Reports dataset** to explore the time and location-based distribution of crimes in Austin, Texas. By analyzing this data, the project aims to identify patterns that could inform targeted crime prevention and resource allocation in the city.

This dataset provides records of crime incidents reported by the Austin Police Department. Each entry documents a unique crime event, including the offense type, date, time, location type, and council district. Understanding these patterns can be important for active policing, as Case Studies on Transport Policy has shown that time-based and location-based policing can significantly reduce crime rates in urban areas by concentrating resources on high-risk times and places.

-   **Dataset Link**: <https://data.austintexas.gov/Public-Safety/Crime-Reports/fdj4-gpfu/about_data>.

-   **Data Structure**:

    -   **Unique Row**: Each row represents an individual crime report filed in Austin.

    -   **Main Variables**:

        -   `Highest Offense Description`: Details the specific crime (e.g., theft, assault).

        -   `Occurred Date Time`: Timestamp of the crime, used to extract `hour`, `date`, and `month` for analysis.

        -   `Location Type`: Broad category indicating the location (e.g., residential, commercial).

        -   `Council District`: Specifies the city district where the crime occurred.

**Research Questions and Expected Insights**:

The exploratory data analysis aims to answer several questions:

1.  **Time Patterns**: When do crimes occur most frequently? Are there specific hours or seasons with higher crime rates?

2.  **Location Patterns**: Which council districts report the highest crime rates? Are certain crime types concentrated in specific locations?

By conducting this analysis, I expect to uncover **peaks in time** for crime, possibly concentrated in late-night hours or specific months (like summer or holiday seasons). I also anticipate that **location patterns** will reveal hotspots in certain districts or location types, such as higher theft rates in commercial areas. These insights could guide resource allocation in Austin, enabling targeted interventions during high-risk times and in high-risk areas.

```{r}
# load the packages
library(tidyverse)
library(dplyr)
library(lubridate)
library(forcats)
library(readr)
library(stringr)

# import data
CrimeReport <- read_csv("~/322E/Project/CrimeReports.csv")

# create a local copy of data
crime_data <- CrimeReport
crime_data
```

### Methods

**Initial Data Structure**: The original dataset contained 86,755 rows and 19 columns. Relevant variables included are the offense description, occurred crime date and time, location type, and council district.

```{r}
# preview the data
head(crime_data)
glimpse(crime_data)
dim(crime_data)
```

#### Data Cleaning and Wrangling

**Categorization**:

-   Created `crime` categories (e.g., Theft, Assault) using the `categorize_crime` function.

-   Created `location` categories (e.g., Residential, Commercial) with `categorize_location` to simplify spatial analysis.

```{r}
# generalize crime types to similar crimes
categorize_crime <- function(offense) {
  case_when(
    offense %in% c("THEFT", "BURGLARY NON RESIDENCE", "THEFT FROM PERSON", 
                   "THEFT OF METAL", "THEFT BY SHOPLIFTING", "THEFT-NO SUSPECT/FOLLOWUP",
                   "THEFT OF LICENSE PLATE", "MAIL THEFT", "THEFT FROM BUILDING",
                   "BURGLARY OF VEHICLE", "BURGLARY OF SHED/DETACHED GARAGE/STORAGE UNIT",
                   "THEFT FROM AUTO", "BURGLARY OF RESIDENCE", "AUTO THEFT") ~ "Theft",
    
    offense %in% c("ASSAULT W/INJURY-FAM/DATE VIOL", "ASSAULT BY CONTACT", 
                   "ASSAULT BY THREAT", "AGG ASSAULT", "ASSAULT WITH INJURY",
                   "ASSAULT BY CONTACT FAM/DATING", "ASSAULT BY THREAT FAM/DATING",
                   "INJURY TO CHILD", "AGG ASLT STRANGLE/SUFFOCATE", "INJ TO ELDERLY FAM/DATE VIOL") ~ "Assault",
    
    offense %in% c("POSS CONTROLLED SUB/NARCOTIC", "POSS CONTROLLED SUB/SYN NARC", 
                   "POSS CONTROLLED SUB/OTHER", "POSS OF DRUG PARAPHERNALIA", 
                   "POSSESSION OF MARIJUANA") ~ "Drug-Related",
    
    offense %in% c("DISTURBANCE - OTHER", "FAMILY DISTURBANCE", 
                   "FAMILY DISTURBANCE/PARENTAL", "DOC FIGHTING", "DOC DISPLAY GUN/DEADLY PUB PLC",
                   "TERRORISTIC THREAT-FAM/DAT VIO", "STALKING", "HARASSMENT", 
                   "DISORDERLY CONDUCT") ~ "Disturbance",
    
    offense %in% c("CRIMINAL TRESPASS", "CRIMINAL MISCHIEF", 
                   "CRIMINAL MISCHIEF-NO SUSPECT", "GRAFFITI", "ARSON", "DAMAGE CITY PROP") ~ "Property Damage",
    
    offense %in% c("DWI", "EVADING VEHICLE", "EVADING / VEHICLE PURSUIT", 
                   "DOC FIGHTING", "VIOL CITY ORDINANCE - OTHER", 
                   "EXPLOSIVE ORDNANCE DISPOSAL", "TRAFFIC VIOLATION") ~ "Traffic Violation",
    
    offense %in% c("FRAUD - OTHER", "FRAUDULENT USE OF ID", 
                   "FRAUD FILING FINANCE STATEMENT", "DEBIT CARD ABUSE", "IDENTITY THEFT") ~ "Fraud",
    
    offense %in% c("UNLAWFUL CARRYING WEAPON", "POSS OF FIREARM BY FELON", 
                   "AIRPORT PLACES WEAPON PROHIBIT", "WEAPONS VIOLATION") ~ "Weapons",
    
    TRUE ~ "Other"
  )
}

# generalize location types to similar locations
categorize_location <- function(location) {
  case_when(
    str_detect(location, "RESIDENCE|APARTMENT|SHELTER|FARM") ~ "Residential",
    str_detect(location, "RESTAURANT|BAR|NIGHTCLUB|COMMERCIAL|OFFICE|DEALERSHIP|MALL|STORE|GROCERY|CONVENIENCE|GAS STATION|SUPERMARKET|SERVICE") ~ "Commercial",
    str_detect(location, "PARK|CHURCH|COMMUNITY|GOVERNMENT|STADIUM|ARENA|DAYCARE|AMUSEMENT") ~ "Public/Community Space",
    str_detect(location, "HWY|ROAD|ALLEY|STREET|SIDEWALK|AIR|BUS|TRAIN|PARKING|GARAGE|DOCK|WHARF|TERMINAL|REST AREA") ~ "Transportation/Transit",
    str_detect(location, "BANK|ATM") ~ "Financial",
    str_detect(location, "SCHOOL|UNIVERSITY|COLLEGE|EDUCATION") ~ "Educational",
    str_detect(location, "INDUSTRIAL|CONSTRUCTION|CASINO|RACE TRACK") ~ "Industrial/Work Sites",
    str_detect(location, "JAIL|PRISON|CORRECTIONS") ~ "Correctional Facility",
    TRUE ~ "Other"  # Catch-all for uncategorized locations
  )
}
```

**Cleaning Steps**:

-   **Date Parsing**: Converted `Occurred Date Time` to separate `date`, `hour`, and `month` components for temporal analysis.

-   **Data Reduction**: Selected relevant columns, resulting in a tidied dataset with 85,791 rows and 6 columns after removing rows with missing values.

-   **Justification for Tidiness**: Each row now represents a single crime incident with clear categories for analysis, making the dataset tidy and ready for analysis.

```{r}
crime_data <- crime_data |>
  rename(
    location_type = `Location Type`,
    council_district = `Council District`
  ) |>
  mutate(
    `Occurred Date Time` = mdy_hm(`Occurred Date Time`),
    hour = hour(`Occurred Date Time`),
    month = month(`Occurred Date Time`, label = TRUE),
    date = as.Date(`Occurred Date Time`),
    crime = categorize_crime(`Highest Offense Description`),
    location = categorize_location(location_type)
  ) |>
  select(crime, hour, month, 
         date, location, council_district) |>
  drop_na()

crime_data
```

### Exploratory Data Analysis

#### **1. Distribution of Crime Types**

**Interpretation**: Theft is the most prevalent crime in Austin, followed by “Other” and “Disturbance.” These findings indicate a need for more resources allocated to preventing theft and disturbances in the city.

```{r}
# crime type distribution
ggplot(crime_data, aes(x = crime)) +
  geom_bar(fill = "skyblue") +
  labs(title = "Distribution of Crime Types", x = "Crime Type", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# summary statistics of the distribution of crime types
crime_summary <- crime_data |>
  group_by(crime) |>
  summarise(count = n()) |>
  mutate(proportion = count / sum(count) * 100) |>
  arrange(desc(count))

crime_summary
```

#### **2. Distribution of Crimes by Hour**

**Interpretation**: Crime rates increase in the evening, peaking around 12 AM. This trend aligns with common nightlife activities and reduced oversight in public areas, indicating potential hotspots for certain crime types at night.

```{r}
# hourly crime distribution
ggplot(crime_data, aes(x = hour)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black") +
  labs(title = "Hourly Distribution of Crimes", x = "Hour of Day", y = "Count") +
  theme_minimal()
```

```{r}
# hourly summary statistics
hourly_summary <- crime_data |>
  group_by(hour) |>
  summarise(count = n()) |>
  summarise(
    mean_count = mean(count),
    max_count = max(count),
    min_count = min(count)
  )

hourly_summary
```

#### **3. Monthly Distribution of Crimes**

**Interpretation**: Crime rates are higher in summer, particularly in July, but peak during March and October which may be linked to increased outdoor and social activities. February has lower crime rates, potentially due to seasonal weather impacts.

```{r}
# monthly crime distribution
ggplot(crime_data, aes(x = month)) +
  geom_bar(fill = "salmon") +
  labs(title = "Monthly Distribution of Crimes", x = "Month", y = "Count") +
  theme_minimal()
```

```{r}
# monthly distribution of crimes Summary
monthly_summary <- crime_data |>
  group_by(month) |>
  summarise(count = n()) |>
  summarise(
    mean_count = mean(count),
    max_count = max(count),
    min_count = min(count)
  )

monthly_summary
```

#### **4. Crime Type by Location**

**Interpretation**: Theft is prevalent in commercial, public spaces, and residential, areas while disturbances are almost exlusively in residential locations. This suggests a need for theft prevention measures in commercial, public, and residential spaces as well as community safety programs in residential neighborhoods.

```{r}
# plot top crime types by location type
ggplot(crime_data, aes(x = location, fill = crime)) +
  geom_bar(position = "dodge") +
  labs(title = "Crime Types by Location Type", 
       x = "Location Type", y = "Crime Count", fill = "Crime Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# crime types by location type summary
crime_location_summary <- crime_data |>
  group_by(location, crime) |>
  summarise(count = n()) |>
  arrange(desc(count)) |>
  group_by(crime) |>
  slice_max(count, n = 1)

crime_location_summary
```

#### **5. Crime Incidents by Council District**

**Interpretation**: Crime rates vary significantly by district, with Districts 3 and 9 experiencing the highest counts. Among all the districts, theft is the number one crime occuring. Targeted interventions in these districts may improve public safety and reduce crime.

```{r}
# aggregate crime counts by council district and crime type
district_crime_data <- crime_data |>
  group_by(council_district, crime) |>
  summarise(count = n(), .groups = 'drop')

# plot crime variation by district
ggplot(district_crime_data, aes(x = factor(council_district), y = count, fill = crime)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Crime Variation by Council District", x = "Council District", y = "Crime Count", fill = "Crime Type") +
  theme_minimal()
```

```{r}
# crime by council district summary
district_summary <- crime_data |>
  group_by(council_district) |>
  summarise(count = n()) |>
  summarise(
    max_district = council_district[which.max(count)],
    max_count = max(count),
    min_district = council_district[which.min(count)],
    min_count = min(count)
  )

district_summary
```

#### **6. Top Crime Types by Hour**:

**Interpretation**: All incidents peak in late evening and early morning hours, and again around noon suggesting that special measures during nighttime and at noon may mitigate these crime types.

```{r}
# crime count by hour and type
ggplot(crime_data, aes(x = hour, color = crime, group = crime)) +
  geom_line(stat = "count", linewidth = 1) +
  labs(title = "Crime Types by Hour of Day", 
       x = "Hour of Day", y = "Crime Count", color = "Crime Type") +
  theme_minimal()
```

```{r}
#  crime by hour summary
crime_hourly_summary <- crime_data |>
  group_by(hour, crime) |>
  summarise(count = n()) |>
  group_by(crime) |>
  summarise(
    avg_count = mean(count),
    max_hour = hour[which.max(count)],
    max_count = max(count)
  )

crime_hourly_summary
```

#### **7. Monthly Crime Trends by Crime Type**:

**Interpretation**: Some crime types exhibit seasonality, with higher instances in specific months. This informs us on the optimal resource allocation for different crime types throughout the year.

```{r}
# aggregate crime counts by month
monthly_crime_data <- crime_data |>
  group_by(month, crime) |>
  summarise(count = n(), .groups = 'drop')

# plot crime trends by month
ggplot(monthly_crime_data, aes(x = month, y = count, color = crime, group = crime)) +
  geom_line(size = 1) +
  labs(title = "Crime Trends by Month", x = "Month", y = "Crime Count", color = "Crime Type") +
  theme_minimal() +
  scale_x_discrete(limits = levels(crime_data$month))  # Ensures months are ordered correctly
```

```{r}
# monthly crime trends by crime type summary
monthly_crime_type_summary <- crime_data |>
  group_by(month, crime) |>
  summarise(count = n()) |>
  group_by(crime) |>
  summarise(
    avg_count = mean(count),
    max_month = month[which.max(count)],
    max_count = max(count)
  )

monthly_crime_type_summary
```

### Machine Learning Model

```{r, warning=FALSE}
library(pROC)
library(caret)

# Clean up the columns
crime_data <- crime_data |>
  mutate(
    location = as.character(location),
    crime = as.character(crime)
  ) |>
  mutate(
    location = as.factor(location),
    crime = as.factor(crime)
  )

# Normalize numeric columns because kNN is a distance metric
crime_data <- crime_data |>
  mutate(
    hour_scaled = scale(hour),
    district_scaled = scale(council_district)
  )

# Creating the model
fit_knn <- knn3(
  crime ~ hour_scaled + district_scaled + location,
  data = crime_data,
  k = 5  # Number of neighbors
)

predictions <- predict(fit_knn, crime_data) |> as.data.frame()
predictions
```

```{r}
# Convert predictions to probabilities for AUC calculation
# (One-vs-All approach: Calculate AUC for each crime type)

# Get all unique crime types
crime_types <- levels(crime_data$crime)  

auc_results <- lapply(crime_types, function(type) {
  roc_response <- as.numeric(crime_data$crime == type)
  roc_predict <- predictions[, type]
  auc(roc(roc_response, roc_predict))
})

# Combine AUC results into a data frame
auc_df <- data.frame(
  Crime_Type = crime_types,
  AUC = unlist(auc_results)
)

auc_df
print(paste("Mean AUC: ",mean(auc_df$AUC)))
```

### Cross-Validation

```{r, warning=FALSE}
# Set number of folds
k <- 5

# Set a seed for reproducibility
set.seed(322)

# Randomly shuffle the rows of the dataset
crime_data <- crime_data[sample(nrow(crime_data)), ]

# Create k folds
folds <- cut(seq(1, nrow(crime_data)), breaks = k, labels = FALSE)
```

```{r}
# Initialize a list to track performance for each crime type across folds
perf_k_all_types <- list()

# Get unique crime types
crime_types <- unique(crime_data$crime)

for (i in 1:k) {
  
  # Split data into train and test data
  train_not_i <- crime_data[folds != i, ]
  test_i <- crime_data[folds == i, ]
  
  # Normalize numeric predictors
  preproc <- preProcess(train_not_i[, c("hour", "council_district")], method = c("center", "scale"))
  train_not_i[, c("hour_scaled", "district_scaled")] <- predict(preproc, train_not_i[, c("hour", "council_district")])
  test_i[, c("hour_scaled", "district_scaled")] <- predict(preproc, test_i[, c("hour", "council_district")])
  
  # Train the model
  train_model <- knn3(
    crime ~ hour_scaled + district_scaled + location,
    data = train_not_i,
    k = 5  # Number of neighbors
  )
  
  # Calculate performance for all crime types
  auc_per_type <- sapply(crime_types, function(type) {
    roc_response <- as.numeric(test_i$crime == type)
    roc_predict <- predict(train_model, test_i)[, type]
    
    # Calculate AUC
    auc(roc(roc_response, roc_predict))
  })
  perf_k_all_types[[i]] <- auc_per_type
}

# Combine AUC results into a data frame
perf_k_df <- do.call(rbind, perf_k_all_types)

# Calculate average and standard deviation of AUC for each crime type
perf_summary <- data.frame(
  Crime_Type = crime_types,
  Mean_AUC = colMeans(perf_k_df, na.rm = TRUE),
  SD_AUC = apply(perf_k_df, 2, sd, na.rm = TRUE)
)
perf_summary
print(paste("Mean AUC: ", mean(perf_summary$Mean_AUC)))
print(paste("Mean SD: ", sd(perf_summary$SD_AUC)))
```

### Results

#### Comparison Between Average Cross-Validation Performance and Overall Model Performance

**Overall Model Performance:** fitting the model to the entire dataset shows reasonably high AUC values for several crime types, such as:

-   Traffic Violation: 0.94

-   Weapons: 0.931

-   Drug-Related: 0.876

-   Fraud: 0.848

However, for some types like "Other" (0.630), "Property Damage" (0.679), and "Assault" (0.670), the performance is lower, indicating difficulties in separating these classes effectively. That said, the model as a whole is fairly good at determining crime types as its average AUC is 0.78.

**Cross-Validation Performance:** The cross-validation results reveal slightly lower AUC values on average, which I expected because cross-validation evaluates the model’s ability to generalize to unseen data:

The highest-performing categories still show strong AUCs:

-   Traffic Violation: 0.882

-   Weapons: 0.798

-   Drug-Related: 0.791

However, the same categories as before – "Property Damage" (0.599), "Assault" (0.612), "Other" (0.572) – underperform. The average AUC for the entire model also follows the same trend (0.72).

**Takeaway**

The average AUC values from cross-validation are slightly lower than the overall model performance, which is expected. The overall performance reflects how well the model fits the dataset it was trained on, whereas cross-validation assesses generalization. Categories like "Traffic Violation" and "Weapons" are being accurately predicted, while others like "Assault" and "Other" remain challenging to model effectively.

#### **How Well Does the Model Predict New Data?**

**Strong Prediction for Some Crime Types:** For categories like "Traffic Violation," "Weapons," and "Drug-Related," the high cross-validated AUCs indicate that the model can effectively predict these crimes on new data, as it consistently distinguishes these classes across folds.

**Weaker Prediction for Others:** The low cross-validated AUCs for "Other," "Property Damage," and "Assault" suggest difficulty in predicting these categories. This may result from:

-   Overlap in the predictors (e.g., similar patterns of occurrence for these crime types).

-   Insufficient distinguishing features in the dataset for these categories.

**Takeaway**

The model is well-suited to predicting specific crime types with clear patterns in the data, such as "Traffic Violation" and "Weapons." However, it struggles with more ambiguous or overlapping classes like "Other" and "Assault," indicating the need for additional predictors or feature engineering to improve performance for these categories. The overall ability for the model to predict what crime happened is good, with an AUC of 0.72.

### Discussion

**Key Patterns in Time and Location:**

-   **Theft**: The most frequent crime type and often concentrated in commercial areas and peaking during late-night hours (8 PM–12 AM). This makes sense since this period has reduced business activity and public oversight.

-   **Traffic Violations**: Very consistent in both location and time, often occurring during peak commuting hours in districts with high traffic density.

-   **Districts 3 and 9:** Consistently reported the highest crime rates, suggesting these are potential hotspots for targeted interventions.

**Modeling Performance:**

-   **High Predictability:** Crimes like traffic violations (AUC: 0.88) and weapons offenses (AUC: 0.80) show strong predictive performance due to clear temporal and spatial patterns.

-   **Low Predictability:** Crimes such as assault (AUC: 0.61) and property damage (AUC: 0.60) are harder to model, likely due to overlapping causes or the lack of specific predictors.

-   **Cross-Validation Results:** Slightly lower average AUCs compared to the overall model fit, reflecting generalization ability. Predictability is consistent for high-performing crime types but remains a challenge for less-defined categories like "other."

-   **Overall: The model performs pretty well with an AUC of 0.78 for the entire dataset and 0.72 when generalizing new data. This means the model is not overfitting or underfitting and is good at generalizing on new data.**

**Implications for Austin:**

-   **District-Specific Interventions:**

    -   **Focus resources in Districts 3 and 9, especially during theft-prone late-night hours.**

-   **Traffic Monitoring:**

    -   **Deploy traffic enforcement during peak hours to reduce violations and related offenses.**

-   **Enhanced Security in Commercial Areas:**

    -   **Strengthen preventive measures, such as surveillance and patrols, to deter theft.**

**Predictive Modeling as a Tool:**

While the model effectively predicts crimes with strong patterns, its limitations for more ambiguous categories really exposes the need for further refinement and feature engineering, requiring more data which is very costly to obtain.

**Ethical Considerations**

Bias in Data Collection:

-   The dataset may overrepresent certain areas, such as Districts 3 and 9, due to systemic biases in policing practices, which could inflate crime statistics.

-   Underreporting in less-policed districts might hide underlying issues. These biases could lead to disproportionate interventions of specific communities.

Community Impact:

-   Predictive policing models must balance the need for proactive interventions with fairness. Transparent use and communication of these tools are important to maintaining trust and preventing potential harm.

-   Poorly implemented models can also very easily lead to false positives, which might alienate the population

Data Collection Practices:

-   Standardize crime type categories and improve consistency in location data to ensure reliable insights.

-   Address gaps in socioeconomic and demographic data, as these are critical for understanding broader crime dynamics.

**Unexpected Insights and Challenges**

Theft Being the Most Common Crime Committed:

-   Theft being the most common crime committed was very surprising because I didn’t expect it to be that common in a city. I had thought that that theft would be more common in suburban areas or areas with a smaller concentration of people.

Weaker Patterns in Certain Crimes:

-   Low AUC values for crimes like assault and property damage highlight the need for additional predictors, such as socioeconomic factors, weather, or real-time incident reporting.

-   There could also be a lot of overlap in their predictors, making it very hard to distinguish between crimes accurately.

Data Limitations:

-   Inconsistencies in location and crime type coding required significant preprocessing, potentially affecting model accuracy as information was lost when putting crimes in buckets.

**Future Directions**

Enhance Data Integration:

-   Use socioeconomic data, weather patterns, and event schedules to provide deeper context for predictions.

-   Transition from council district-level data to more granular neighborhood or hotspot-specific insights.

Expand Analytical Scope:

-   Conduct time-series analyses to evaluate long-term trends in crime rates and assess the impact of past interventions.

-   Investigate patterns within more specific crime categories to find deeper, underlying patterns.

### Reflection, Acknowledgments, and References

**Reflection:**

Challenges Faced:

-   Data Preparation: Consolidating the dataset into a tidy format was one of the most demanding aspects because of inconsistencies in the Location Type and Highest Offense Description fields. Custom categorizations for crime types and locations required me to carefully create groupings.

-   Modeling Complexities: Certain crime categories, such as "Other" or "Property Damage," were harder to model due to overlapping patterns or insufficient distinguishing features in the dataset. These challenges really revealed the limitations of working with real-world, imperfect data.

-   Feature Engineering: The lack of contextual variables, such as socioeconomic factors, weather, or real-time events, limited the model’s ability to improve predictions for less structured crime types.

Lessons Learned:

-   Data Cleaning and Categorization: Handling real-world data showed the importance of structured and consistent data entry, as small inconsistencies can significantly affect analyses. Developing efficient cleaning pipelines using R improved data accuracy and interpretability.

-   Model Evaluation: Cross-validation is a robust framework to evaluate a model’s ability to  generalize, revealing strengths for predictable crime types and limitations for ambiguous categories.

**Acknowledgments:**

I would like to express my gratitude to Professor Guyot and the teaching assistants for their valuable guidance throughout the project. Their feedback greatly enhanced the rigor of my data analysis and interpretation. Special thanks to the City of Austin’s Open Data Portal for making crime data publicly accessible, enabling this study to contribute actionable insights.

**References:**

Dataset:

Austin Crime Reports, available from the City of Austin’s Open Data Portal:

<https://data.austintexas.gov/Public-Safety/Crime-Reports/fdj4-gpfu/about_data>

Background Research:

Kuo, Pei-Fen, et al. “A Promising Example of Smart Policing: A Cross-National Study of the Effectiveness of a Data-Driven Approach to Crime and Traffic Safety.” Case Studies on Transport Policy, Elsevier, 5 Sept. 2019. <https://www.sciencedirect.com/science/article/pii/S2213624X19301336.>

Whitworth, Adam. “Local Inequality and Crime: Exploring How Variation in the Scale of Inequality Measures Affects Relationships Between Inequality and Crime.” Urban Studies, vol. 50, no. 4, 29 Aug. 2012, pp. 725–741. <https://doi.org/10.1177/0042098012455716>.

**External Resources:**

-   dplyr: Documentation for data manipulation functions.

    -   <https://dplyr.tidyverse.org/>

-   ggplot2: Documentation for data visualization functions.

    -   <https://ggplot2.tidyverse.org/>

-   caret: Comprehensive guide for training and evaluating machine learning models.

    -   <https://topepo.github.io/caret/>

-   pROC: Documentation for Receiver Operating Characteristic (ROC) curve analysis and AUC calculation.

    -   <https://cran.r-project.org/web/packages/pROC/index.html>
